{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5224b905",
   "metadata": {},
   "source": [
    "*Your Name*\n",
    "\n",
    "*Collaborator's Names*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c182784-1e25-4a18-8ed3-4ddb0bfb8cf9",
   "metadata": {},
   "source": [
    "# Timing, Testing, and Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85b3cf2-da8b-4fcf-9740-85465bbfd097",
   "metadata": {},
   "source": [
    "Before we make changes to any code, we should establish a baseline with **timing measurements** and **tests**. A baseline timing measurement lets us compare any changes to assess improvement (or degradations!) while tests ensure that our code remains accurate. Improving code performance doesn't help us if we introduce bugs!\n",
    "Best practice would be to implement a [unit test](https://www.techtarget.com/searchsoftwarequality/definition/unit-testing) for every unique feature of a program, but any testing is better than none.\n",
    "\n",
    "After establishing a baseline, we should employ **profiling** to uncover the parts of our program that would benefit most from optmization. We probably already have an idea as to what parts of our code are the slowest. Profiling lets us test our hypotheses. For instance, if we have a function that is executed only once and a function that is executed a thousand times, we might assume it's best to optimize the function executed a thousand times. But profiling might reveal that the function executed only a single time dominates our \"wall time\" (the real-world time that passes as measured by a clock on the wall)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0057c4c9-6b83-4e8f-96a5-5306db001b72",
   "metadata": {},
   "source": [
    "---\n",
    "## Timing Code Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a3f7dd-8bb1-41c6-9875-261a8a3089c7",
   "metadata": {},
   "source": [
    "We'll cover two ways of timing blocks of code. Each is slightly different and has its own pros and cons. You're free to choose which method you prefer for your work in this class, and can switch between methods as you prefer. You are also welcome to research alternative methods.\n",
    "\n",
    "The methods we will cover are:\n",
    "* the `timeit` magic command\n",
    "* the `time` module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a3626d-8304-403a-86e2-9c0b8887aca3",
   "metadata": {},
   "source": [
    "### Timeit magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56a5a96-e675-4ae5-b5c4-0542ba9a872f",
   "metadata": {},
   "source": [
    "Jupyter notebooks allow for special, non-Python commands that act on a given line or cell. These commands are called \"magic.\"\n",
    "\n",
    "One magic command is `timeit`, which provides a quick way for measuring the performance of some code.\n",
    "\n",
    "The `timeit` magic command can either be used on a single line with `%timeit` or on a whole cell with `%%timeit`.\n",
    "\n",
    "Execute the code below to see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcccd51-b348-4364-a0c7-45c853dba586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%timeit np.ones(10) # time just array creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12a9cca-c2cf-473f-b7fc-c8b99e430ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit # time whole cell; list creation and append loop\n",
    "lst = []\n",
    "for i in range(100):\n",
    "    lst.append(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d99504-1b34-443f-9737-a09a2a092166",
   "metadata": {
    "tags": []
   },
   "source": [
    "Both versions of the `timeit` magic command report the average runtime and its standard deviation.\n",
    "\n",
    "The output also references **loops** and **runs**. The `timeit` command will execute our code multiple times (the loops) during one measurement to increase accuracy. It will then repeat this timing measurement over multiple runs in order to measure the mean and standard deviation.\n",
    "\n",
    "An example of two runs with four loops each is shown in the diagram below. \n",
    "\n",
    "![Diagram explaining loops and runs as used by timeit](loop-run-diagram.png)\n",
    "\n",
    "One full execution of a hypothetical program is represented by the orange blocks. The program is looped over and executed four times per run. The execution time measured by each run $r_1$ and $r_2$ would then be $(t_1-t_0)/4$. These runs can then be used to report an average runtime and a standard deviation. For example, the average runtime of the program represented by the orange block is $(r_1 + r_2) / 2$\n",
    "\n",
    "Using repeated runs for measurement are important because the CPU will not be executing our code 100% of the time. It will instead switch between operating system tasks and other programs, such as the web browser you are running this notebook in. You will never be able to prevent this \"context switching\" but it can cause variation in timing measurements. Using multiple runs lets us statistically characterize the performance of our program.\n",
    "\n",
    "On the other hand, using multiple loops per run let's us better measure the run time of a program, particularly if it is very short. Timing measurements don't have infinite precision and there is a minimum time difference that can be measured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a595aff9-50e5-4d5c-8e57-c71615171557",
   "metadata": {},
   "source": [
    "---\n",
    "#### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762a8017-bdd9-4b52-bf99-3e6b09b075a8",
   "metadata": {},
   "source": [
    "1. Add the `timeit` magic command to the following code. **Don't** time how long it takes to import the `time` module. We're using `time.sleep` to make the computer pause for 1 second and simulate a longer-running piece of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3442ef-138f-446b-875a-9671920d92cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b5de5c-6f7a-43af-9aa5-c62369bcabfb",
   "metadata": {},
   "source": [
    "2. How does the number of loops and runs compare to the `timeit` examples above? Why is the number of loops different?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4b389f-ed19-4dc9-8358-b8ac4ad66bf7",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b268b2ba-4195-4490-b6ce-8fab38aa6b35",
   "metadata": {},
   "source": [
    "---\n",
    "### Time Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a84f9e2-daf1-4947-a71f-1801130f4e5d",
   "metadata": {},
   "source": [
    "Often in this course we'll want to see how execution time changes as we adjust various parameters and then plot the results. Though the `timeit` magic command makes timing a short piece of code easy, it is tedious to use for this kind of analysis.\n",
    "\n",
    "As an alternative, we can use the `time` module. This module is able to return timestamps. We can use the difference in these timestamps to measure our code's execution time.\n",
    "\n",
    "Timing execution in this way isn't as robust as using `timeit` because it doesn't automatically perform multiple loops or runs, but it does make it easier to repeat timing measurements within a `for` loop, for example. We can manually decided to find the average and standard deviation if we wish.\n",
    "\n",
    "There are two functions we might consider using, depending on our desired precision:\n",
    "\n",
    "* `time.perf_counter`\n",
    "* `time.perf_counter_ns`\n",
    "\n",
    "While `time.perf_counter` returns time in (fractional) seconds, `time.perf_counter_ns` returns the time in nanoseconds. For shorter run times, it's better to use `time.perf_counter_ns` to avoid floating point errors. Both of these functions return timestamps that only make sense when compared against each other.\n",
    "\n",
    "These functions measure the amount of real time (or **wallclock time**) that has passed, which includes the time that passes when the process sleeps so the CPU can switch to other tasks. The amount of time the CPU spends on other tasks will introduce some variability into the resulting execution time. Both of these `perf_counter` functions return timestamps with the highest precision measurable by the computer.\n",
    "\n",
    "Run the following cell to see `perf_counter` in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b25bc-33e3-4744-ae4f-306965b9d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "lst = []\n",
    "for i in range(100):\n",
    "    lst.append(i)\n",
    "\n",
    "end = time.perf_counter()\n",
    "\n",
    "print(\"This code took\", (end - start), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492e4ac1-d119-4ce7-bd7b-297b0b9553ae",
   "metadata": {},
   "source": [
    "---\n",
    "#### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c0efdd-8c34-42ea-aef6-5298f3fa6fc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. Rerun the `perf_counter` example a couple of times and notice the variation in timing measurements. This is what `timeit` is trying to account for by using multiple runs. What's the highest value you've seen? What's the lowest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc516f5-6db6-4379-88d5-55dace917ef0",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d532aec2-7ae7-4ebf-9e9b-72a9ee084339",
   "metadata": {},
   "source": [
    "2. The `perf_counter` example runs the same code as the `%%timeit` example from above. Compare the timing measurements returned by these two measurements. Are they different? Which seems to be higher? Google something like \"perf_counter vs timeit\" to do some research on subtle differences between these approaches that might explain this difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7469c77-11b5-4ac2-8c97-43e7848e44b6",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926a1fec-72ac-4d74-87b6-c6799c3e92fa",
   "metadata": {},
   "source": [
    "3. Time the following block of code for array sizes `n` of 10, 100, 1000, and 10000. Use both `perf_counter` in a `for` loop and `timeit`, and plot both results. Make sure to include **axis labels and a legend**. Put your code in the following cells as indicated by the comments.\n",
    "\n",
    "```python\n",
    "arr = np.arange(n) # change n\n",
    "csum = 0\n",
    "for num in arr:\n",
    "    csum += num\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8467be08-fd00-402a-ba0f-6a6078ce8a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perf_counter in a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85081203-3b9e-4d3b-9deb-3b21e5144acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee433918-2b2c-4988-9c06-83fde86395a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot both measurements\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49af6d9b-93d9-4951-a7a8-a80706676aac",
   "metadata": {},
   "source": [
    "4. In what instance would you *personally* prefer to use `timeit`? When would you prefer to use `time.perf_counter`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1a5f40-f8ec-4581-adbb-eee2f7ef7f22",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b9ed8c-b3f2-40f5-bfc8-ea5e1e89ab44",
   "metadata": {},
   "source": [
    "---\n",
    "## Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadad35b-4b55-456e-b9b8-b7d0d6997fbc",
   "metadata": {},
   "source": [
    "\"Profiling\" ones code means gathering data about how the program is executed. Some common questions that profiling can answer are:\n",
    "\n",
    "* What part of the code does the program spend the most time in?\n",
    "* What code represents the slowest part of my program?\n",
    "* How much memory is my program using?\n",
    "\n",
    "Answering such questions allows us to identify targets for **optimization**.\n",
    "\n",
    "Usually, profiling code execution times and memory usage require different tools. We will focus on execution time in this course. In particular, we'll use two magic commands: `prun` and `lprun`.\n",
    "\n",
    "For this exercise, we'll use a program to calculate [Julia sets](https://en.wikipedia.org/wiki/Julia_set) modified from [High Performance Python by Gorelick & Ozsvald](https://github.com/mynameisfiber/high_performance_python_2e/tree/master/02_profiling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498a1144-a52a-42a4-8d0b-3357320982cf",
   "metadata": {},
   "source": [
    "### The Julia Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993ac3a6-bb49-410e-9a68-51c76e826772",
   "metadata": {},
   "source": [
    "Julia sets are defined by picking a complex point $c$; for instance, $c=-0.62772 - j0.42193$ where $j$ is the imaginary number. For a set of complex coordinates $z$, the coordinate $z$ belongs to the Julia set if the iteration $z^\\prime = z^2+c$ remains less than 2. \n",
    "\n",
    "The following code applies this test, putting a cap on the maximum number of iterations used to test each coordinate $z$. We save the number of iterations `n_iter` used to test each coordinate $z$. We will use the built-in [`complex`](https://docs.python.org/2/library/stdtypes.html#numeric-types-int-float-long-complex) type for our imaginary numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c11b438-9967-431c-b903-e0b6a39d0179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_julia(zs, c, max_iter):\n",
    "    \"\"\"\n",
    "    Given a complex coordinate c and a list of complex coordinates zs,\n",
    "    test whether each z in zs belongs to the Julia set defined by c.\n",
    "    \n",
    "    Return the number of iterations n_iter needed to determine\n",
    "    whether or not each z is in the set.\n",
    "    \n",
    "    The number of iterations is capped by max_iter.\n",
    "    \"\"\"\n",
    "    output = [0] * len(zs) # create list of zeros with length len(zs)\n",
    "\n",
    "    for i in range(len(zs)):\n",
    "        n_iter = 0\n",
    "        z = zs[i]\n",
    "        while abs(z) < 2 and n_iter < max_iter:\n",
    "            z = z * z + c\n",
    "            n_iter += 1\n",
    "        output[i] = n_iter\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f136cab0-872d-4d76-b9c4-739392c2f609",
   "metadata": {},
   "source": [
    "We can then write a function that constructs a grid of $z = x + jy$ coordinates and plots the number of iterations needed to test each $z$. The lightest points belong to the Julia set, while darker points require fewer iterations to exclude them from the set. This is the most common way of visualizing Julia sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc7042a-da8d-495e-aa40-ebb045987944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_julia_set(c, x1, x2, y1, y2,\n",
    "                   width=1000, max_iterations=300, draw_output=False):\n",
    "    \"\"\"\n",
    "    Create a list of complex coordinates zs where z = x + iy\n",
    "    and test whether these points belong to the Julia set\n",
    "    defined by c. Optionally plot the resuling set.\n",
    "\n",
    "    Returns the sum of iterations needed to test all zs.\n",
    "    \n",
    "    The lower and upper bounds of x and y \n",
    "    are defined by x1, x2, y1, and y2.\n",
    "    The width controls the number of coordinates \n",
    "    between the minimum and maximum.\n",
    "    Control the maximum number of iterations for testing each\n",
    "    coordinate z with max_iterations.\n",
    "    Control plotting with draw_output.\n",
    "    \"\"\"\n",
    "    # Construct lists of x and y (real and imaginary) coordinates\n",
    "    x_step = (x2 - x1) / width\n",
    "    y_step = (y1 - y2) / width\n",
    "    x = []\n",
    "    y = []\n",
    "    ycoord = y2\n",
    "    while ycoord > y1:\n",
    "        y.append(ycoord)\n",
    "        ycoord += y_step\n",
    "    xcoord = x1\n",
    "    while xcoord < x2:\n",
    "        x.append(xcoord)\n",
    "        xcoord += x_step\n",
    "\n",
    "    # Combine x and y into a list of complex z coordinates\n",
    "    zs = []\n",
    "    for ycoord in y:\n",
    "        for xcoord in x:\n",
    "            zs.append(complex(xcoord, ycoord))\n",
    "\n",
    "    # Print information about dimensionality\n",
    "    print(\"Length of x:\", len(x))\n",
    "    print(\"Total elements:\", len(zs))\n",
    "\n",
    "    # Calculate the Julia set\n",
    "    output = test_julia(zs, c, max_iterations)\n",
    "\n",
    "    # Optionally plot the set\n",
    "    if draw_output:\n",
    "        plt.pcolormesh(x, y, np.reshape(output, (width, width)))\n",
    "\n",
    "    return sum(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fc82c9-669d-47bb-9e03-59c1d6b707e6",
   "metadata": {},
   "source": [
    "With our functions defined, let's set our parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7cd95b-7489-4371-a738-97c26b95c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_init = complex(-0.62772, -0.42193)\n",
    "print(\"c is\", c_init)\n",
    "\n",
    "x_min, x_max = -1.8, 1.8\n",
    "y_min, y_max = -1.8, 1.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9f8fda-a5be-4cc9-8055-602885ea6235",
   "metadata": {},
   "source": [
    "For the default `width` and `max_iterations`, we expect `sum(output)` to be 33219980. We can use this to test the correctness of our function as we make changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eedbeaf-afa0-4ee7-9e99-944e1368f7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_sum = 33219980"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61fc414-e3bd-4a5f-b25f-59ec5c2cb778",
   "metadata": {},
   "source": [
    "---\n",
    "#### Exercise\n",
    "\n",
    "Calculate, display, and verify the Julia set for `c_init` and the x and y bounds defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6979837-6a76-4fb5-a039-27602aa820af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Julia set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f552bd2-1b05-4371-b69d-258df9884534",
   "metadata": {},
   "source": [
    "---\n",
    "### Profiling the Julia Set Calculation\n",
    "\n",
    "Programs are often long and complex. A developer following best practices will split such a program into functions; but even if the developer doesn't, a program will still likely rely on a number of functions built into Python and any imported modules (such as NumPy). A **function-by-function** profiler such as the magic command `prun` will return timing information for all functions used in a program, both user-defined and otherwise. This timing information will also include the number of times a program was called. \n",
    "\n",
    "It's generally safe to assume that any function not written by you -- that is, a function in a module or built into Python -- is already optmizied.\n",
    "\n",
    "After identifying *functions* that could benefit from optimization, you may want to turn to a **line-by-line** profiler such as the `%lprun` magic command provided by the `line_profiler` module (aka \"kernprof\"). **This module can also be invoked inside [scripts](https://kernprof.readthedocs.io/en/latest/) run from the command line.** Such a profiler will give you information on the performance of individual lines of code.\n",
    "\n",
    "We'll practice parsing the output of `%prun` and `%lprun`. If you ever want more information about these magic commands, you can run them with a question mark; e.g. `%prun?`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe57103c-d7d3-4910-b2e5-3760207588d5",
   "metadata": {},
   "source": [
    "---\n",
    "#### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213163bb-3037-4134-abac-0241190504b3",
   "metadata": {},
   "source": [
    "1. Before we start, which function used by `calc_julia_set` do you think consumes the most time? Remember that even a short function called many times can contribute significantly to the overall wall time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7657eec5-4556-4704-aaf8-1a933f5c2b79",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb61b7cb-3fa1-498e-af64-2398c0a16cfb",
   "metadata": {},
   "source": [
    "2. Use `%prun` to profile `calc_julia_set` function-by-function. Disable drawing to see fewer functions. Can you identify the user-defined functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feccccd-1af9-45b3-89e6-69f125906b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile calc_julia_set with prun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5523fdea-d983-48a8-bac3-3e92ae996191",
   "metadata": {},
   "source": [
    "3. Explain what each of the columns means. In particular, what is the difference between `totttime` and `cumtime`? Notice the total run time near the top of the output. Google is allowed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bc8efb-1fbc-47f8-86cc-30bf2a0c06cd",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baad9607-7770-40d9-842e-acf93be2d00b",
   "metadata": {},
   "source": [
    "4. The output says functions are ordered by \"internal time.\" What do you think \"internal time\" is referring to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfadfeb-9628-4189-90aa-f6975695c226",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f212253-a373-42ae-96e9-387dbdc51844",
   "metadata": {},
   "source": [
    "5. The `lprun` magic command works a little differntly than `prun`. Since it is provided by a module, we must first load it with `%load_ext`. Then, we must specify a function name with the `-f` argument. We can specify multiple functions by using `-f` multiple times, but `lprun` will *only* profile the functions we specify. Modify the following cells to profile **the user-defined function that `prun` ranked as taking the most internal time**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04753501-286d-40a1-85cd-849d43047579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lprun is an external magic command\n",
    "%load_ext line_profiler\n",
    "\n",
    "# Profile calc_julia_set; EDIT THE LINE BELOW\n",
    "%lprun -f <function_name> calc_julia_set(c_init, x_min, x_max, y_min, y_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f62777-a7d5-423c-af88-d300fe714c05",
   "metadata": {},
   "source": [
    "6. Explain what each of the columns mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07a5f74-30bf-4083-bfb9-e9fe55ed77a3",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377ec6c1-a4ac-4a6c-8f6b-d99f08df0eb8",
   "metadata": {},
   "source": [
    "7. Explain the different number of \"Hits\" for each line. Why do some lines hit 1 million times? Why do some hit more? Others only once?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7986c65-aeec-4e49-aa6e-905935037ec0",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80327300-ec5b-484d-b873-e658c325ed02",
   "metadata": {},
   "source": [
    "8. Which line do you think is the best target for optimization? Justify using the stats provided by `lprun`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f6d42d-cbbb-463e-b90e-1ad4fb766e51",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecfb3a9-da10-4dad-9d8a-edec3d963c88",
   "metadata": {},
   "source": [
    "---\n",
    "## Application: Improving the Julia Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5739a1e6-bdf6-4efc-9040-ba3bfee1fc21",
   "metadata": {},
   "source": [
    "We've learned multiple ways to time and profile our code and we've seen one simple way of testing the Julia set program. Now, you'll employ these skills to improve the wall clock time of the Julia set program.  Create new cells as needed to complete these tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d30e882-9b0d-4cba-a01e-b3ea8532e6ef",
   "metadata": {},
   "source": [
    "1. First, perform a timing measurement of `calc_julia_set` to establish a baseline. You can either include the plotting stage or not, but whatever option you choose, you should be consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f086f-3e42-40f1-ba9e-4f90c0d86a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9fade-853c-4b86-a5b4-2e1e7a9d5e95",
   "metadata": {},
   "source": [
    "*Timing result here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797db90-4f41-4059-acd7-70c280a5e18f",
   "metadata": {},
   "source": [
    "2. You've already identified the ideal candidate for optimization in the previous section: the statement `while abs(z) < 2 and n_iter < max_iter`. This statement is evaluating two conditions on the same line. Which expression is faster to evaluate, `abs(z) < 2` or `n_iter < max_iter`? Why do you think that is?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463e54c4-9d12-491d-bad9-5422d59720a0",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75826b3c-7148-40d0-82de-53a2fd04ab6a",
   "metadata": {},
   "source": [
    "3. An important part of profiling and refactoring is developing and testing hypotheses. Currently, the `while` statement evaluates `abs(z) < 2` even if the loop is on its final iteration. This represents unnecessary work which we might be able to remove for a performance gain.\n",
    "Before class you were asked to review [Python Operator Precedence](https://introcs.cs.princeton.edu/python/appendix_precedence/). \n",
    "How can you use this information to rewrite the `while` statement and avoid unnecessary work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1683fa-3bcc-4378-956e-5cd153d783e9",
   "metadata": {},
   "source": [
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7755dbd4-10ce-4a09-852f-8929ec4c1065",
   "metadata": {},
   "source": [
    "4. Rewrite `test_julia` (ideally making a renamed copy) to include the optimization you came up with above. Update `calc_julia_set` as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd342b1-7dc0-4e6f-959a-4c5ae339ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ab371-f1d3-4377-8339-5f02c1b86917",
   "metadata": {},
   "source": [
    "5. Test your updated version of `calc_julia_set` to ensure your changes to `test_julia` didn't change the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10a56d9-a4a8-4327-bff3-f31dd20ab926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365aeced-1381-4ef8-9e4a-efa7acbaa08c",
   "metadata": {},
   "source": [
    "6. Time your updated version of `calc_julia_set`. What was the result of testing our hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72fd20-8f35-479c-b58c-173b89a1f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea83c1e-2d54-4533-8ec4-dc226c424c63",
   "metadata": {},
   "source": [
    "*Timing result here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92b4f8e",
   "metadata": {},
   "source": [
    "## For Next Class\n",
    "\n",
    "Read:\n",
    "\n",
    "* Read **all pages** of this overview on the [basics of the CPU](https://www.bbc.co.uk/bitesize/guides/zws8d2p/revision/1).\n",
    "* Watch [this video](https://thecrashcourse.com/courses/data-structures-crash-course-computer-science-14/) on data structures. This video is not specific to Python. The first roughly 6 minutes are the most relevant for our next class, but you may find all of it interesting and informative.\n",
    "* Read the accompanying PDF on Lists and Tuples to understand how these data structures function under the hood.\n",
    "* **If you've never used NumPy,** I suggest reading the [beginner guide](https://numpy.org/doc/stable/user/absolute_beginners.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
